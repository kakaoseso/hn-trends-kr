---
title: "1MHz 8비트 CPU에서 CNN을 돌린다고? Rémi Coulom의 6809 프로젝트"
description: "1MHz 8비트 CPU에서 CNN을 돌린다고? Rémi Coulom의 6809 프로젝트"
pubDate: "2026-01-29T15:41:23Z"
---

최근 엔지니어링 미팅에 들어가면 온통 GPU 이야기뿐입니다. "H100 클러스터 확보했나요?", "이번 모델 파라미터가 너무 커서 VRAM에 안 올라갑니다", "Inference Latency가 너무 길어요." 솔직히 말해서, 우리 업계가 컴퓨팅 리소스를 물 쓰듯 쓰는 데 너무 익숙해진 건 아닌가 하는 생각이 들 때가 많습니다.

그런데 오늘 아침, 제 눈을 의심케 하는 논문 하나를 발견했습니다. **Motorola 6809** 8비트 마이크로프로세서에서 Deep Convolutional Neural Network(CNN)를 구동해 보드게임을 플레이한다는 내용입니다. 1979년에 나온 그 1MHz짜리 CPU 말입니다.

더 놀라운 건 저자입니다. **Rémi Coulom**. 바둑 AI 역사에 관심 있는 분이라면 모를 수가 없는 이름이죠. 몬테카를로 트리 탐색(MCTS)의 선구자이자 'Crazy Stone'의 개발자입니다. 이 정도 레벨의 엔지니어가 레트로 하드웨어에서 딥러닝을 돌렸다면, 이건 단순한 장난감 프로젝트가 아니라 '극한의 최적화' 교과서일 가능성이 큽니다.

오늘은 이 기이하고도 경이로운 프로젝트를 통해 우리가 잊고 있던 최적화의 본질을 이야기해 보려 합니다.

## 1. 6809 CPU: 제약 사항의 미학

먼저 하드웨어 스펙을 봅시다. Motorola 6809는 8비트 시대의 명기(Masterpiece)로 불립니다. 6502나 Z80보다 나중에 나와서 아키텍처가 훨씬 깔끔하고, 16비트 연산을 지원하는 인덱스 레지스터도 있죠. 하지만 딥러닝 관점에서는 절망적입니다.

- **Clock Speed:** 1~2 MHz (GHz가 아닙니다)
- **RAM:** 보통 64KB (GB가 아닙니다)
- **FPU:** 없음 (Floating Point? 꿈도 꾸지 마십시오)

우리가 PyTorch에서 `model.to('cuda')` 한 줄로 처리하는 행렬 연산을, 여기서는 덧셈과 시프트 연산만으로, 그것도 수 KB의 메모리 안에서 해결해야 합니다.

## 2. 어떻게 구현했을까? (Technical Deep Dive)

논문의 핵심은 결국 **Quantization(양자화)** 과 **효율적인 메모리 접근** 일 것입니다. 32비트 float 연산은 8비트 CPU에서 재앙에 가깝습니다. 소프트웨어적으로 부동소수점을 구현하면 추론 한 번에 몇 분이 걸릴지도 모릅니다.

### Extreme Quantization
Rémi는 아마도 **8-bit Integer** 혹은 그 이하의 bit-width를 사용했을 겁니다. 최근 Edge AI에서 유행하는 TinyML 기법들이 40년 전 하드웨어에 강제로 적용된 셈입니다. 가중치(Weight)와 활성화(Activation) 값을 모두 정수로 변환하고, 복잡한 활성화 함수(Sigmoid, Tanh)는 Lookup Table로 대체하거나 ReLU 같은 단순한 연산으로 처리했을 것입니다.

### Assembly Optimization
6809는 인덱스 레지스터(`X`, `Y`, `U`)가 강력해서 포인터 연산에 유리합니다. CNN의 핵심인 Convolution 연산은 메모리 접근 패턴이 매우 규칙적입니다. C 컴파일러에 의존하지 않고, 직접 어셈블리어로 레지스터 할당을 최적화하여 **Zero-overhead loop** 를 구현했을 가능성이 높습니다. 현대 CPU의 SIMD(AVX 등)가 하는 일을 수작업으로 Unrolling 했다고 보시면 됩니다.

## 3. 왜 이런 짓(?)을 하는가

"그냥 M2 맥북 쓰면 되잖아요?"라고 묻는 주니어 엔지니어가 있다면, 저는 이렇게 대답해주고 싶습니다. **"제약이 혁신을 만든다."**

우리는 지금 LLM의 시대에 살고 있지만, 동시에 On-device AI의 시대이기도 합니다. 스마트폰, IoT 센서, 심지어 전력 제약이 심한 임베디드 장비에서 AI를 돌려야 할 니즈는 폭발하고 있습니다. 1MHz CPU에서 CNN을 돌리기 위해 고민했던 테크닉들(메모리 정렬, 캐시 효율성, 정수 연산 최적화)은 최신 ARM Cortex-M 시리즈나 RISC-V 칩셋에서 NPU를 설계할 때 필요한 마인드셋과 정확히 일치합니다.

Rémi Coulom 같은 거장이 이런 프로젝트를 하는 건, 단순히 레트로 감성 때문만은 아닐 겁니다. 밑바닥부터(From Scratch) 연산을 재정의하면서 얻는 통찰은 고수준 프레임워크만 만지는 엔지니어는 절대 얻을 수 없는 자산입니다.

## 4. 마치며: 엔지니어의 자세

이 프로젝트를 보며 반성하게 됩니다. 우리는 너무 쉽게 "리소스 더 늘려주세요"라고 말하곤 합니다. 코드가 느리면 최적화를 하기보다 서버를 스케일업하는 게 더 싸게 먹히는 세상이니까요. 하지만 엔지니어로서의 'Craftsmanship(장인 정신)'은 이런 극한의 상황에서 빛을 발합니다.

이 논문은 단순한 레트로 게임 구현기가 아닙니다. **"컴퓨팅 파워가 부족한 게 아니라, 네 코드가 비효율적인 거야"** 라고 말하는 듯한, 거장의 따끔한 일침입니다.

### References
- **Original Article:** https://ipsj.ixsq.nii.ac.jp/records/229345
- **Hacker News Thread:** https://news.ycombinator.com/item?id=46810337
